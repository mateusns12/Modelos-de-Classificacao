{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import layers\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(nome_arquivo,shuffle):\n",
    "    ds = pd.read_csv(nome_arquivo,encoding=\"utf-8\")\n",
    "    if shuffle:\n",
    "        ds = ds.sample(frac=1)\n",
    "    ds['texto'] = ds['texto'].apply(str)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words(\"portuguese\"))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    filtered_words = [word.lower() for word in text.split() if word.lower() not in stop]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "def remove_URL(text):\n",
    "    url = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "    return url.sub(r\"\",text)\n",
    "\n",
    "def remove_punct(text):\n",
    "    translator = str.maketrans(\"\",\"\",'!\"\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~º')\n",
    "    translator = str.maketrans(\"\",\"\",'!\"\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~º')\n",
    "    return text.translate(translator)\n",
    "\n",
    "def remove_numbers(text):\n",
    "    result = ''.join([i for i in text if not i.isdigit()])\n",
    "    return result\n",
    "\n",
    "def remove_hifen(text):\n",
    "    translator = str.maketrans('-',' ')\n",
    "    return text.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r\"https?//(\\S+|www)\\.\\S+\")\n",
    "def pat(df_t):\n",
    "    for t in df_t.texto:\n",
    "        matches = pattern.findall(t)\n",
    "        for match in  matches:\n",
    "            print(t)\n",
    "            print(match)\n",
    "            print(pattern.sub(r\"\",t))        \n",
    "        if len(matches)> 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test(df_t):\n",
    "    df_t[\"texto\"] = df_t.texto.map(remove_URL)\n",
    "    df_t[\"texto\"] = df_t.texto.map(remove_punct)\n",
    "    df_t[\"texto\"] = df_t.texto.map(remove_hifen)\n",
    "    #df_t[\"texto\"] = df_t.texto.map(remove_numbers)\n",
    "    df_t[\"texto\"] = df_t.texto.map(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter_word(text_col):\n",
    "    count = Counter()\n",
    "    for text in text_col.values:\n",
    "        for word in text.split():\n",
    "            count[word] += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(df,size):\n",
    "    train_size = int(df.shape[0]*size)\n",
    "    train_df = df[:train_size]\n",
    "    val_df = df[train_size:]\n",
    "    return train_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_numpy(df):    \n",
    "    train_sentences = train_df.texto.to_numpy()\n",
    "    train_labels = train_df.valor.to_numpy()\n",
    "    val_sentences = val_df.texto.to_numpy()\n",
    "    val_labels = val_df.valor.to_numpy()\n",
    "    return train_sentences, train_labels, val_sentences, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(teste):\n",
    "    teste = remove_URL(teste)\n",
    "    teste = remove_punct(teste)\n",
    "    teste = remove_hifen(teste)\n",
    "    teste = remove_stopwords(teste)    \n",
    "    return teste\n",
    "\n",
    "def predict(teste):\n",
    "    predictions = model.predict(np.array(teste)) \n",
    "    p1 = [np.argmax(element) for element in predictions]\n",
    "    if p1[0]:\n",
    "        print(\"Disciplina: Eletronica\")\n",
    "    else:\n",
    "        print(\"Disciplina: Elétrica\")\n",
    "    return predictions,p1\n",
    "\n",
    "def tokenization(df):      \n",
    "    tokenizer.fit_on_texts(train_sentences)\n",
    "    word_index = tokenizer.word_index\n",
    "    train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "    val_sequences = tokenizer.texts_to_sequences(val_sentences)\n",
    "    return train_sequences, val_sequences, word_index\n",
    "\n",
    "def decode(sequence):\n",
    "    return \" \".join([reverse_word_index.get(idx, \"?\") for idx in sequence])\n",
    "\n",
    "def precision(test_labels,predictions):\n",
    "    counter = len(test_labels)\n",
    "    list_c = [i for i,j in zip(predictions,test_labels) if i == j]\n",
    "    return len(list_c)/counter*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data('train.csv',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1420, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valor</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>7</td>\n",
       "      <td>O setor da construção civil é responsável por ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>6</td>\n",
       "      <td>Apresento neste trabalho as experiências que m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>7</td>\n",
       "      <td>Este trabalho teve como objetivos propor e apl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>7</td>\n",
       "      <td>Economia Circular é um conceito transdisciplin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>4</td>\n",
       "      <td>A Osteotomia Sagital Bilateral é uma das técni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      valor                                              texto\n",
       "1059      7  O setor da construção civil é responsável por ...\n",
       "1017      6  Apresento neste trabalho as experiências que m...\n",
       "1024      7  Este trabalho teve como objetivos propor e apl...\n",
       "1136      7  Economia Circular é um conceito transdisciplin...\n",
       "627       4  A Osteotomia Sagital Bilateral é uma das técni..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "198\n",
      "200\n",
      "103\n",
      "120\n",
      "199\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "print((df.valor==1).sum())#eletronica\n",
    "print((df.valor==2).sum())#direito\n",
    "print((df.valor==3).sum())#eletrica\n",
    "print((df.valor==4).sum())#odontologia\n",
    "print((df.valor==5).sum())#computação\n",
    "print((df.valor==6).sum())#geografia\n",
    "print((df.valor==7).sum())#ambiental\n",
    "print((df.valor==8).sum())#mecanica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat(df)\n",
    "make_test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trabalho', 1484),\n",
       " ('sistema', 928),\n",
       " ('estudo', 784),\n",
       " ('análise', 671),\n",
       " ('ser', 662)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = counter_word(df.texto)\n",
    "num_unique_words = len(counter)\n",
    "counter.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1136\n",
      "284\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = data_split(df,0.8)\n",
    "\n",
    "print(len(train_df))\n",
    "print(len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1136,), (284,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences, train_labels, val_sentences, val_labels = data_to_numpy(df)\n",
    "train_sentences.shape, val_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = num_unique_words,oov_token=\"<OOV>\")\n",
    "train_sequences, val_sequences, word_index = tokenization(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1136, 500), (284, 500))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 500\n",
    "\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding = \"post\",truncating = \"post\")\n",
    "val_padded = pad_sequences(val_sequences, maxlen = max_length, padding = \"post\", truncating = \"post\")\n",
    "train_padded.shape, val_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = dict([(idx,word) for (word, idx) in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(layers.LSTM(32,dropout = 0.1))\n",
    "#model.add(layers.Conv1D(128,1,activation='relu'))\n",
    "#model.add(layers.Dense(128, activation = \"relu\"))\n",
    "#model.add(layers.Bidirectional(layers.LSTM(32)))\n",
    "#model.add(layers.Dense(720, activation = \"relu\"))\n",
    "#model.add(layers.Dense(128, activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 32)           716288    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 72)                2376      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 9)                 657       \n",
      "=================================================================\n",
      "Total params: 719,321\n",
      "Trainable params: 719,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(layers.Embedding(num_unique_words, 32, input_length = max_length))\n",
    "\n",
    "model.add(layers.GlobalAveragePooling1D())\n",
    "\n",
    "model.add(layers.Dense(72,activation = \"relu\"))\n",
    "\n",
    "model.add(layers.Dense(9, activation = \"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "optim = keras.optimizers.Adam(lr=0.001)\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "model.compile(loss=loss, optimizer = optim, metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "36/36 - 1s - loss: 2.1780 - accuracy: 0.1496 - val_loss: 2.1493 - val_accuracy: 0.1303\n",
      "Epoch 2/50\n",
      "36/36 - 0s - loss: 2.1233 - accuracy: 0.1496 - val_loss: 2.0899 - val_accuracy: 0.1303\n",
      "Epoch 3/50\n",
      "36/36 - 0s - loss: 2.0768 - accuracy: 0.1479 - val_loss: 2.0621 - val_accuracy: 0.1338\n",
      "Epoch 4/50\n",
      "36/36 - 0s - loss: 2.0506 - accuracy: 0.1532 - val_loss: 2.0399 - val_accuracy: 0.1585\n",
      "Epoch 5/50\n",
      "36/36 - 0s - loss: 2.0279 - accuracy: 0.2826 - val_loss: 2.0200 - val_accuracy: 0.2746\n",
      "Epoch 6/50\n",
      "36/36 - 0s - loss: 1.9996 - accuracy: 0.2896 - val_loss: 1.9979 - val_accuracy: 0.2676\n",
      "Epoch 7/50\n",
      "36/36 - 0s - loss: 1.9588 - accuracy: 0.4630 - val_loss: 1.9557 - val_accuracy: 0.4613\n",
      "Epoch 8/50\n",
      "36/36 - 0s - loss: 1.9023 - accuracy: 0.4375 - val_loss: 1.9022 - val_accuracy: 0.3873\n",
      "Epoch 9/50\n",
      "36/36 - 0s - loss: 1.8264 - accuracy: 0.4780 - val_loss: 1.8383 - val_accuracy: 0.4965\n",
      "Epoch 10/50\n",
      "36/36 - 0s - loss: 1.7293 - accuracy: 0.5141 - val_loss: 1.7602 - val_accuracy: 0.4930\n",
      "Epoch 11/50\n",
      "36/36 - 0s - loss: 1.6163 - accuracy: 0.5704 - val_loss: 1.6578 - val_accuracy: 0.4542\n",
      "Epoch 12/50\n",
      "36/36 - 0s - loss: 1.4977 - accuracy: 0.6329 - val_loss: 1.5634 - val_accuracy: 0.5810\n",
      "Epoch 13/50\n",
      "36/36 - 0s - loss: 1.3737 - accuracy: 0.6945 - val_loss: 1.4631 - val_accuracy: 0.6444\n",
      "Epoch 14/50\n",
      "36/36 - 0s - loss: 1.2490 - accuracy: 0.7324 - val_loss: 1.3674 - val_accuracy: 0.6549\n",
      "Epoch 15/50\n",
      "36/36 - 0s - loss: 1.1366 - accuracy: 0.7773 - val_loss: 1.2826 - val_accuracy: 0.6585\n",
      "Epoch 16/50\n",
      "36/36 - 0s - loss: 1.0336 - accuracy: 0.7614 - val_loss: 1.2062 - val_accuracy: 0.6514\n",
      "Epoch 17/50\n",
      "36/36 - 0s - loss: 0.9446 - accuracy: 0.7729 - val_loss: 1.1401 - val_accuracy: 0.7042\n",
      "Epoch 18/50\n",
      "36/36 - 0s - loss: 0.8645 - accuracy: 0.8081 - val_loss: 1.0847 - val_accuracy: 0.7007\n",
      "Epoch 19/50\n",
      "36/36 - 0s - loss: 0.7928 - accuracy: 0.8231 - val_loss: 1.0350 - val_accuracy: 0.7077\n",
      "Epoch 20/50\n",
      "36/36 - 0s - loss: 0.7308 - accuracy: 0.8275 - val_loss: 0.9908 - val_accuracy: 0.7148\n",
      "Epoch 21/50\n",
      "36/36 - 0s - loss: 0.6692 - accuracy: 0.8477 - val_loss: 0.9606 - val_accuracy: 0.7183\n",
      "Epoch 22/50\n",
      "36/36 - 0s - loss: 0.6187 - accuracy: 0.8460 - val_loss: 0.9177 - val_accuracy: 0.7254\n",
      "Epoch 23/50\n",
      "36/36 - 0s - loss: 0.5643 - accuracy: 0.8600 - val_loss: 0.8830 - val_accuracy: 0.7359\n",
      "Epoch 24/50\n",
      "36/36 - 0s - loss: 0.5187 - accuracy: 0.8776 - val_loss: 0.8589 - val_accuracy: 0.7324\n",
      "Epoch 25/50\n",
      "36/36 - 0s - loss: 0.4775 - accuracy: 0.8680 - val_loss: 0.8382 - val_accuracy: 0.7359\n",
      "Epoch 26/50\n",
      "36/36 - 0s - loss: 0.4395 - accuracy: 0.9269 - val_loss: 0.8136 - val_accuracy: 0.7500\n",
      "Epoch 27/50\n",
      "36/36 - 0s - loss: 0.4026 - accuracy: 0.9023 - val_loss: 0.7941 - val_accuracy: 0.7465\n",
      "Epoch 28/50\n",
      "36/36 - 0s - loss: 0.3709 - accuracy: 0.9173 - val_loss: 0.7827 - val_accuracy: 0.7359\n",
      "Epoch 29/50\n",
      "36/36 - 0s - loss: 0.3391 - accuracy: 0.9445 - val_loss: 0.7735 - val_accuracy: 0.7465\n",
      "Epoch 30/50\n",
      "36/36 - 0s - loss: 0.3146 - accuracy: 0.9261 - val_loss: 0.7680 - val_accuracy: 0.7500\n",
      "Epoch 31/50\n",
      "36/36 - 0s - loss: 0.2876 - accuracy: 0.9516 - val_loss: 0.7458 - val_accuracy: 0.7606\n",
      "Epoch 32/50\n",
      "36/36 - 0s - loss: 0.2626 - accuracy: 0.9551 - val_loss: 0.7424 - val_accuracy: 0.7535\n",
      "Epoch 33/50\n",
      "36/36 - 0s - loss: 0.2424 - accuracy: 0.9657 - val_loss: 0.7271 - val_accuracy: 0.7817\n",
      "Epoch 34/50\n",
      "36/36 - 0s - loss: 0.2232 - accuracy: 0.9692 - val_loss: 0.7171 - val_accuracy: 0.7852\n",
      "Epoch 35/50\n",
      "36/36 - 0s - loss: 0.2034 - accuracy: 0.9806 - val_loss: 0.7202 - val_accuracy: 0.7676\n",
      "Epoch 36/50\n",
      "36/36 - 0s - loss: 0.1854 - accuracy: 0.9780 - val_loss: 0.7141 - val_accuracy: 0.7817\n",
      "Epoch 37/50\n",
      "36/36 - 0s - loss: 0.1711 - accuracy: 0.9798 - val_loss: 0.7188 - val_accuracy: 0.7746\n",
      "Epoch 38/50\n",
      "36/36 - 0s - loss: 0.1567 - accuracy: 0.9815 - val_loss: 0.7012 - val_accuracy: 0.7958\n",
      "Epoch 39/50\n",
      "36/36 - 0s - loss: 0.1432 - accuracy: 0.9815 - val_loss: 0.7099 - val_accuracy: 0.7746\n",
      "Epoch 40/50\n",
      "36/36 - 0s - loss: 0.1315 - accuracy: 0.9868 - val_loss: 0.6896 - val_accuracy: 0.7958\n",
      "Epoch 41/50\n",
      "36/36 - 0s - loss: 0.1210 - accuracy: 0.9894 - val_loss: 0.6906 - val_accuracy: 0.7958\n",
      "Epoch 42/50\n",
      "36/36 - 0s - loss: 0.1103 - accuracy: 0.9930 - val_loss: 0.6887 - val_accuracy: 0.7782\n",
      "Epoch 43/50\n",
      "36/36 - 0s - loss: 0.1018 - accuracy: 0.9921 - val_loss: 0.6939 - val_accuracy: 0.7746\n",
      "Epoch 44/50\n",
      "36/36 - 0s - loss: 0.0947 - accuracy: 0.9938 - val_loss: 0.6878 - val_accuracy: 0.7993\n",
      "Epoch 45/50\n",
      "36/36 - 0s - loss: 0.0876 - accuracy: 0.9956 - val_loss: 0.6949 - val_accuracy: 0.7641\n",
      "Epoch 46/50\n",
      "36/36 - 0s - loss: 0.0814 - accuracy: 0.9956 - val_loss: 0.6856 - val_accuracy: 0.7852\n",
      "Epoch 47/50\n",
      "36/36 - 0s - loss: 0.0758 - accuracy: 0.9956 - val_loss: 0.6887 - val_accuracy: 0.7817\n",
      "Epoch 48/50\n",
      "36/36 - 0s - loss: 0.0698 - accuracy: 0.9965 - val_loss: 0.6952 - val_accuracy: 0.7711\n",
      "Epoch 49/50\n",
      "36/36 - 0s - loss: 0.0651 - accuracy: 0.9965 - val_loss: 0.6863 - val_accuracy: 0.7923\n",
      "Epoch 50/50\n",
      "36/36 - 0s - loss: 0.0613 - accuracy: 0.9965 - val_loss: 0.6937 - val_accuracy: 0.7711\n",
      "\n",
      "Finished in 9.73 second(s)\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "model.fit(train_padded,train_labels, epochs = 50, validation_data=(val_padded,val_labels), verbose=2)\n",
    "finish = time.perf_counter()\n",
    "print(f'\\nFinished in {round(finish-start, 2)} second(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(val_padded)\n",
    "predictions = [np.argmax(element) for element in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  5\n",
      "Resultado:  1 \n",
      "\n",
      "[5 4 4 8 8 2 2 2 2 1 4 2 7 7 5 6 8 8 7 8 2 7 5 6 5 1 1 6 6 2 6 5 2 4 1 2 7\n",
      " 3 7 4 5 4 6 8 8 2 3 1 6 4 6 8 2 4 8 8 3 6 2 3 1 1 6 4 3 1 6 5 6 3 8 1 1 6\n",
      " 8 3 2 7 4 2 2 1 7 6 2 6 8 2 1 1 1 3 3 6 1 4 6 5 5 8 6 7 7 1 2 5 6 2 1 6 3\n",
      " 6 5 1 1 4 8 4 2 3 8 4 3 6 5 1 4 8 2 2 3 8 7 6 3 1 7 6 6 7 3 1 4 8 4 1 5 3\n",
      " 6 2 8 1 8 1 3 2 3 7 3 3 3 6 3 7 2 6 8 4 7 5 1 1 3 7 2 8 6 2 8 2 8 3 5 2 1\n",
      " 3 8 6 2 2 1 6 7 7 3 7 4 2 7 8 2 8 2 8 7 6 8 6 3 8 3 3 2 3 6 8 4 7 2 6 8 5\n",
      " 8 7 1 6 8 7 6 1 1 3 6 1 2 6 3 6 3 2 1 2 8 2 3 6 6 7 7 7 3 5 3 7 5 1 2 6 1\n",
      " 2 8 5 8 8 1 1 1 6 4 3 4 4 6 2 2 7 2 7 8 1 2 8 7 8] \n",
      "\n",
      "[1, 4, 4, 8, 8, 2, 2, 2, 2, 1, 4, 2, 7, 7, 5, 6, 8, 8, 7, 8, 2, 7, 1, 6, 1, 1, 1, 2, 7, 2, 6, 5, 6, 4, 1, 2, 7, 3, 6, 4, 5, 4, 6, 8, 8, 2, 3, 5, 7, 4, 6, 8, 2, 4, 8, 8, 2, 6, 6, 3, 1, 1, 6, 4, 1, 1, 6, 1, 6, 1, 8, 1, 1, 7, 8, 8, 2, 7, 4, 2, 2, 1, 7, 6, 2, 6, 8, 2, 5, 1, 3, 3, 3, 7, 1, 4, 6, 1, 1, 1, 6, 7, 7, 1, 6, 1, 6, 2, 3, 6, 1, 6, 1, 3, 1, 4, 8, 4, 2, 3, 8, 4, 1, 6, 1, 8, 4, 8, 2, 2, 3, 8, 8, 6, 3, 1, 6, 6, 6, 7, 3, 1, 4, 8, 4, 1, 5, 3, 6, 6, 8, 1, 8, 1, 1, 2, 3, 7, 3, 8, 1, 6, 3, 8, 2, 6, 8, 4, 7, 1, 3, 1, 3, 7, 2, 1, 6, 2, 8, 2, 8, 3, 5, 2, 1, 3, 8, 6, 2, 2, 8, 6, 8, 7, 3, 7, 4, 2, 7, 8, 2, 8, 2, 8, 8, 6, 8, 6, 2, 8, 2, 3, 2, 1, 6, 8, 4, 7, 2, 6, 8, 3, 8, 6, 1, 6, 8, 7, 6, 3, 1, 1, 6, 1, 2, 6, 3, 6, 8, 2, 1, 2, 8, 2, 3, 6, 6, 7, 7, 3, 1, 1, 3, 7, 5, 3, 2, 6, 8, 6, 8, 1, 8, 6, 1, 8, 2, 6, 4, 8, 4, 4, 6, 6, 2, 7, 2, 7, 8, 1, 6, 8, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "#print(\"Sentença: \",val_sentences[0])\n",
    "print(\"Label: \",val_labels[0])\n",
    "print(\"Resultado: \",predictions[0],'\\n')\n",
    "print(val_labels,'\\n')\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.11267605633803\n"
     ]
    }
   ],
   "source": [
    "r = precision(val_labels,predictions)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = get_data('eval.csv',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valor</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Este projeto visa uma nova abordagem para um s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Nesta monografia, é apresentada a proposta de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Este Trabalho de Conclusão de Curso tem por fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>O presente estudo tem como principal objetivo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Na atualidade, a produção termelétrica partici...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   valor                                              texto\n",
       "0      1  Este projeto visa uma nova abordagem para um s...\n",
       "1      1  Nesta monografia, é apresentada a proposta de ...\n",
       "2      2  Este Trabalho de Conclusão de Curso tem por fi...\n",
       "3      2  O presente estudo tem como principal objetivo ...\n",
       "4      3  Na atualidade, a produção termelétrica partici..."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat(ds)\n",
    "make_test(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = ds.texto.to_numpy()\n",
    "test_labels = ds.valor.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding = \"post\",truncating = \"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8]\n",
      "93.75\n"
     ]
    }
   ],
   "source": [
    "predictions_t = model.predict(test_padded)\n",
    "predictions_t = [np.argmax(element) for element in predictions_t]\n",
    "print(predictions_t)\n",
    "\n",
    "print(precision(test_labels,predictions_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
