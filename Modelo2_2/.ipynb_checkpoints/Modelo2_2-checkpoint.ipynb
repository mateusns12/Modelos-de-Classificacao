{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(nome_arquivo):\n",
    "    ds = pd.read_csv(nome_arquivo,encoding=\"utf-8\")\n",
    "    ds = ds.sample(frac=1)\n",
    "    ds['texto'] = ds['texto'].apply(str)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valor</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1</td>\n",
       "      <td>O presente trabalho tem como propósito apresen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>Devido ao  grande  aumento do consumo de energ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>O objetivo deste trabalho  é evidenciar os gan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1</td>\n",
       "      <td>Desde o decreto n° 5.163 de julho de 2004, ond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>Este trabalho consiste no desenvolvimento de m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     valor                                              texto\n",
       "194      1  O presente trabalho tem como propósito apresen...\n",
       "45       1  Devido ao  grande  aumento do consumo de energ...\n",
       "33       1  O objetivo deste trabalho  é evidenciar os gan...\n",
       "157      1  Desde o decreto n° 5.163 de julho de 2004, ond...\n",
       "11       1  Este trabalho consiste no desenvolvimento de m..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194    O presente trabalho tem como propósito apresen...\n",
       "45     Devido ao  grande  aumento do consumo de energ...\n",
       "33     O objetivo deste trabalho  é evidenciar os gan...\n",
       "157    Desde o decreto n° 5.163 de julho de 2004, ond...\n",
       "11     Este trabalho consiste no desenvolvimento de m...\n",
       "                             ...                        \n",
       "336    Em virtude da significativa importância que as...\n",
       "230    O presente trabalho propõe uma análise conjunt...\n",
       "179    Com o propósito de ser uma fonte de energia el...\n",
       "358    O presente trabalho se volta à análise do inst...\n",
       "67     Esse trabalho descreve uma análise preliminar ...\n",
       "Name: texto, Length: 398, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "198\n"
     ]
    }
   ],
   "source": [
    "print((df.valor==1).sum())#eletrica\n",
    "print((df.valor==0).sum())#direito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def remove_URL(text):\n",
    "    url = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "    return url.sub(r\"\",text)\n",
    "\n",
    "def remove_punct(text):\n",
    "    translator = str.maketrans(\"\",\"\",'!\"\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~º')\n",
    "    return text.translate(translator)\n",
    "\n",
    "def remove_hifen(text):\n",
    "    translator = str.maketrans('-',' ')\n",
    "    return text.translate(translator)\n",
    "\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r\"https?//(\\S+|www)\\.\\S+\")\n",
    "for t in df.texto:\n",
    "    matches = pattern.findall(t)\n",
    "    for match in  matches:\n",
    "        print(t)\n",
    "        print(match)\n",
    "        print(pattern.sub(r\"\",t))\n",
    "        \n",
    "    if len(matches)> 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"texto\"] = df.texto.map(remove_URL)\n",
    "df[\"texto\"] = df.texto.map(remove_punct)\n",
    "df[\"texto\"] = df.texto.map(remove_hifen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Mateus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = set(stopwords.words(\"portuguese\"))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    filtered_words = [word.lower() for word in text.split() if word.lower() not in stop]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"texto\"] = df.texto.map(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def counter_word(text_col):\n",
    "    count = Counter()\n",
    "    for text in text_col.values:\n",
    "        for word in text.split():\n",
    "            count[word] += 1\n",
    "    return count\n",
    "\n",
    "counter = counter_word(df.texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9292"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trabalho', 443),\n",
       " ('sistema', 314),\n",
       " ('energia', 286),\n",
       " ('análise', 241),\n",
       " ('estudo', 218)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_words = len(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(df.shape[0]*0.8)\n",
    "\n",
    "train_df = df[:train_size]\n",
    "val_df = df[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = train_df.texto.to_numpy()\n",
    "train_labels = train_df.valor.to_numpy()\n",
    "\n",
    "val_sentences = val_df.texto.to_numpy()\n",
    "val_labels = val_df.valor.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((318,), (80,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences.shape, val_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words = num_unique_words,oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "val_sequences = tokenizer.texts_to_sequences(val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((318, 500), (80, 500))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_length = 500\n",
    "\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding = \"post\",truncating = \"post\")\n",
    "val_padded = pad_sequences(val_sequences, maxlen = max_length, padding = \"post\", truncating = \"post\")\n",
    "train_padded.shape, val_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = dict([(idx,word) for (word, idx) in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(sequence):\n",
    "    return \" \".join([reverse_word_index.get(idx, \"?\") for idx in sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1163]\n",
      "resumo\n"
     ]
    }
   ],
   "source": [
    "decoded_text = decode(train_sequences[10])\n",
    "\n",
    "print(train_sequences[10])\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 32)           297344    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                3096      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 305,289\n",
      "Trainable params: 305,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.Embedding(num_unique_words, 32, input_length = max_length))\n",
    "\n",
    "#model.add(layers.LSTM(256,dropout = 0.1))\n",
    "model.add(layers.GlobalAveragePooling1D())\n",
    "model.add(layers.Dense(128, activation = \"relu\"))\n",
    "model.add(layers.Dense(24, activation = \"relu\"))\n",
    "model.add(layers.Dense(24, activation = \"relu\"))\n",
    "#model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "model.add(layers.Softmax())\n",
    "model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "optim = keras.optimizers.Adam(lr=0.001)\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "model.compile(loss=loss, optimizer = optim, metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10/10 - 1s - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6929 - val_accuracy: 0.5125\n",
      "Epoch 2/30\n",
      "10/10 - 0s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6929 - val_accuracy: 0.5125\n",
      "Epoch 3/30\n",
      "10/10 - 0s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.5125\n",
      "Epoch 4/30\n",
      "10/10 - 0s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.5125\n",
      "Epoch 5/30\n",
      "10/10 - 0s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.5125\n",
      "Epoch 6/30\n",
      "10/10 - 0s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6929 - val_accuracy: 0.5125\n",
      "Epoch 7/30\n",
      "10/10 - 0s - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6929 - val_accuracy: 0.5125\n",
      "Epoch 8/30\n",
      "10/10 - 0s - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6929 - val_accuracy: 0.5125\n",
      "Epoch 9/30\n",
      "10/10 - 0s - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6928 - val_accuracy: 0.5125\n",
      "Epoch 10/30\n",
      "10/10 - 0s - loss: 0.6930 - accuracy: 0.5000 - val_loss: 0.6928 - val_accuracy: 0.5125\n",
      "Epoch 11/30\n",
      "10/10 - 0s - loss: 0.6927 - accuracy: 0.5000 - val_loss: 0.6925 - val_accuracy: 0.5125\n",
      "Epoch 12/30\n",
      "10/10 - 0s - loss: 0.6923 - accuracy: 0.5000 - val_loss: 0.6921 - val_accuracy: 0.5125\n",
      "Epoch 13/30\n",
      "10/10 - 0s - loss: 0.6914 - accuracy: 0.5000 - val_loss: 0.6914 - val_accuracy: 0.5125\n",
      "Epoch 14/30\n",
      "10/10 - 0s - loss: 0.6897 - accuracy: 0.5000 - val_loss: 0.6894 - val_accuracy: 0.6625\n",
      "Epoch 15/30\n",
      "10/10 - 0s - loss: 0.6859 - accuracy: 0.9371 - val_loss: 0.6855 - val_accuracy: 0.8250\n",
      "Epoch 16/30\n",
      "10/10 - 0s - loss: 0.6777 - accuracy: 0.9686 - val_loss: 0.6767 - val_accuracy: 0.9750\n",
      "Epoch 17/30\n",
      "10/10 - 0s - loss: 0.6601 - accuracy: 0.9874 - val_loss: 0.6571 - val_accuracy: 0.9500\n",
      "Epoch 18/30\n",
      "10/10 - 0s - loss: 0.6166 - accuracy: 1.0000 - val_loss: 0.6111 - val_accuracy: 0.9000\n",
      "Epoch 19/30\n",
      "10/10 - 0s - loss: 0.5481 - accuracy: 0.9780 - val_loss: 0.5524 - val_accuracy: 0.9750\n",
      "Epoch 20/30\n",
      "10/10 - 0s - loss: 0.5010 - accuracy: 1.0000 - val_loss: 0.5204 - val_accuracy: 0.9750\n",
      "Epoch 21/30\n",
      "10/10 - 0s - loss: 0.4788 - accuracy: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.9375\n",
      "Epoch 22/30\n",
      "10/10 - 0s - loss: 0.4657 - accuracy: 1.0000 - val_loss: 0.4869 - val_accuracy: 0.9750\n",
      "Epoch 23/30\n",
      "10/10 - 0s - loss: 0.4551 - accuracy: 0.9969 - val_loss: 0.4779 - val_accuracy: 0.9750\n",
      "Epoch 24/30\n",
      "10/10 - 0s - loss: 0.4452 - accuracy: 1.0000 - val_loss: 0.4687 - val_accuracy: 0.9875\n",
      "Epoch 25/30\n",
      "10/10 - 0s - loss: 0.4371 - accuracy: 1.0000 - val_loss: 0.4622 - val_accuracy: 0.9750\n",
      "Epoch 26/30\n",
      "10/10 - 0s - loss: 0.4297 - accuracy: 1.0000 - val_loss: 0.4570 - val_accuracy: 0.9625\n",
      "Epoch 27/30\n",
      "10/10 - 0s - loss: 0.4232 - accuracy: 1.0000 - val_loss: 0.4455 - val_accuracy: 0.9750\n",
      "Epoch 28/30\n",
      "10/10 - 0s - loss: 0.4167 - accuracy: 1.0000 - val_loss: 0.4446 - val_accuracy: 0.9750\n",
      "Epoch 29/30\n",
      "10/10 - 0s - loss: 0.4110 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.9750\n",
      "Epoch 30/30\n",
      "10/10 - 0s - loss: 0.4058 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.9500\n",
      "\n",
      "Finished in 2.53 second(s)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.perf_counter()\n",
    "model.fit(train_padded,train_labels, epochs = 30, validation_data=(val_padded,val_labels), verbose=2)\n",
    "finish = time.perf_counter()\n",
    "print(f'\\nFinished in {round(finish-start, 2)} second(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(val_padded)\n",
    "#print(predictions)\n",
    "predictions = [1 if p > 0.5 else 0 for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.0  %\n"
     ]
    }
   ],
   "source": [
    "def precision(predictions,labels):\n",
    "    counter = len(labels)\n",
    "    list_c = [i for i,j in zip(predictions,labels) if i == j]\n",
    "    return counter,len(list_c)\n",
    "\n",
    "t,p = precision(predictions,val_labels)\n",
    "print(p*100/t,\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  1\n",
      "Resultado:  1 \n",
      "\n",
      "[1 0 1 1 1 1 0 1 1 1 0 0 0 1 0 0 0 0 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 1 1 0 1\n",
      " 0 1 0 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 1 1 1 1\n",
      " 1 0 0 1 0 1] \n",
      "\n",
      "[1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "index = 7\n",
    "#print(val_sentences[index])\n",
    "#print(val_padded[index],'\\n')\n",
    "print(\"Label: \",val_labels[index])\n",
    "print(\"Resultado: \",predictions[index],'\\n')\n",
    "print(val_labels,'\\n')\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s = pd.read_csv(\"eval.csv\")\n",
    "df_t = df_s.sample(frac=1)\n",
    "#df_t = pd.read_csv(\"eval.csv\")\n",
    "df_t['texto'] = df_t['texto'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valor</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Os conversores CC-CA são elementos de Eletrôni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>O presente estudo analisa a responsabilidade c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>O presente trabalho foi idealizado a partir da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ante ao implemento em tecnologia dos ilícitos ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>O Objetivo é demonstrar, com a apresentação do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   valor                                              texto\n",
       "7      1  Os conversores CC-CA são elementos de Eletrôni...\n",
       "2      0  O presente estudo analisa a responsabilidade c...\n",
       "6      1  O presente trabalho foi idealizado a partir da...\n",
       "0      0  Ante ao implemento em tecnologia dos ilícitos ...\n",
       "1      0  O Objetivo é demonstrar, com a apresentação do..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test():\n",
    "    df_t[\"texto\"] = df_t.texto.map(remove_URL)\n",
    "    df_t[\"texto\"] = df_t.texto.map(remove_punct)\n",
    "    df_t[\"texto\"] = df_t.texto.map(remove_hifen)\n",
    "    df_t[\"texto\"] = df_t.texto.map(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pat():\n",
    "    for t in df_t.texto:\n",
    "        matches = pattern.findall(t)\n",
    "        for match in  matches:\n",
    "            print(t)\n",
    "            print(match)\n",
    "            print(pattern.sub(r\"\",t))        \n",
    "        if len(matches)> 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat()\n",
    "make_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    conversores cc ca elementos eletrônica potênci...\n",
       "2    presente estudo analisa responsabilidade civil...\n",
       "6    presente trabalho idealizado partir experiênci...\n",
       "0    ante implemento tecnologia ilícitos contra ord...\n",
       "1    objetivo demonstrar apresentação números ofici...\n",
       "3    fato legislação brasileira adotou expressament...\n",
       "5    linguagem xml extensible markup language consi...\n",
       "4    trabalho objetivo analisar motor partida conve...\n",
       "Name: texto, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = df_t.texto.to_numpy()\n",
    "test_labels = df_t.valor.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 7, 391, 136, 91, 2180, 5787, 5788, 418, 37, 5789, 55, 338, 810, 646, 882, 256, 346, 2180, 5790, 5791, 2166, 2515, 197, 1153, 837, 5792, 1122, 3385, 2303, 1810, 314, 95, 136, 91, 1966, 5793, 712, 446, 2455, 5794, 36, 134, 74, 5795, 175, 530, 174, 481, 1747, 1359, 5796, 5797, 5798, 20, 481, 648, 975, 1966, 5799, 978, 346, 232, 1110, 1392, 1074, 17, 319, 29, 62, 230, 331, 407, 531, 118, 1392, 2516, 5800, 2517, 3338, 1004, 115, 19, 157, 1814, 9, 39, 5801, 128, 198, 2298, 222, 105, 39]\n"
     ]
    }
   ],
   "source": [
    "#print(test_sentences)\n",
    "print(test_sequences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding = \"post\",truncating = \"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.65567636]\n",
      " [0.31650078]\n",
      " [0.6507616 ]\n",
      " [0.31653476]\n",
      " [0.31662115]\n",
      " [0.31657976]\n",
      " [0.6562964 ]\n",
      " [0.6534811 ]]\n"
     ]
    }
   ],
   "source": [
    "predictions_t = model.predict(test_padded)\n",
    "print(predictions_t)\n",
    "predictions_t = [1 if p > 0.5 else 0 for p in predictions_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 0 0 1 1]\n",
      "[1, 0, 1, 0, 0, 0, 1, 1]\n",
      "100.0  %\n"
     ]
    }
   ],
   "source": [
    "index = 6\n",
    "#print(test_sentences)#[index])\n",
    "\n",
    "print(test_labels)#[index])\n",
    "print(predictions_t)#[index])\n",
    "\n",
    "def precision_t():\n",
    "    counter = len(test_labels)\n",
    "    list_c = [i for i,j in zip(predictions_t,test_labels) if i == j]\n",
    "    return counter,len(list_c)\n",
    "t,p = precision_t()\n",
    "print(p*100/t,\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ante implemento tecnologia ilícitos contra ordem econômica manutenção jogo limpo players disputa mercado estado viuse obrigado adotar novos meios investigação apurar infrações momento consensualização direito busca instituto delação premiada meio prova criminal instrumento mantém ordem econômica presente trabalho objetivo demonstrar direito econômico transformou instituto delação premiada instrumento manutenção ordem econômica enfoca utilização acordos leniência instrumento combate atos anticompetitivos examina efeitos utilização acordos esfera administrativa criminal cível apurar eficiência instrumentos natureza delatória regulação mercado contrapondo objetivos atingidos principais críticas formuladas respeito prática'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.texto[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_test = decode(test_sequences[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trabalho objetivo analisar motor partida convencional motor elétrico corrente contínua excitação série abordam etapas funcionamento partida funções peças compõem motor partida analisam características elétrico construtivas motor apoio software baseado métodos elementos finitos pode visualizar configuração eletromagnética interna motor fim realizam simulações dinâmica desse motor confirmam viabilidade uso desse tipo motor corrente contínua partida motores combustão\n"
     ]
    }
   ],
   "source": [
    "print(decoded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('m_salvo/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('modelo_completo/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    " teste_2 = \"Este trabalho descreve o projeto de um carregador de baterias tipo chumbo-ácido controlado por um microcontrolador, utilizando os princípios e técnicas da eletrônica de potência. O sistema será capaz de carregar um banco de baterias composto por até seis baterias dispostas em série, controlando o processo de carga para garantir a integridade do sistema e otimizar a vida útil das mesmas, utilizando métodos inteligentes para o processo de carga. O banco de baterias pertence a um projeto em andamento que trata do desenvolvimento de um veículo náutico autônomo.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_2 = remove_URL(teste_2)\n",
    "teste_2 = remove_punct(teste_2)\n",
    "teste_2 = remove_hifen(teste_2)\n",
    "teste_2 = remove_stopwords(teste_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trabalho descreve projeto carregador baterias tipo chumbo ácido controlado microcontrolador utilizando princípios técnicas eletrônica potência sistema capaz carregar banco baterias composto seis baterias dispostas série controlando processo carga garantir integridade sistema otimizar vida útil mesmas utilizando métodos inteligentes processo carga banco baterias pertence projeto andamento trata desenvolvimento veículo náutico autônomo'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = tokenizer.texts_to_sequences([teste_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 500) for input KerasTensor(type_spec=TensorSpec(shape=(None, 500), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 50).\n",
      "[[0.656445]]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "predictions_t2 = model.predict(np.array(texto))\n",
    "print(predictions_t2)\n",
    "predictions_t2 = [1 if p > 0.5 else 0 for p in predictions_t2]\n",
    "\n",
    "print(predictions_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_3 = \"Este trabalho de conclusão de curso teve como objetivo simular e analisar a cascata energética do rio tietê que pertencem a aes-tietê. As usinas hidrelétricas que foram estudas são: barra bonita, bariri, ibitinga, promissão e nova avanhandava. Para simulação foi usado o software mike basin 2000. E a satisfação, que pode ser definida como a probabilidade de atendimento das demandas totais do sistema foi usada para análise. Foram simulados dois cenários: o primeiro representando um caso atual, onde foram escolhidos os anos de 1998 à 2007 e segundo um caso crítico. Este último foram escolhido as dez piores médias anuais entre os anos de 1931 à 2007. Em relação ao cenário 1, que representa os últimos dez anos de vazões naturais, observou uma grande satisfação em todas as usinas hidrelétricas, mesmo tendo alguns períodos de seca. Chegou até verter água na uhe de nova avanhandava. O cenário 2 demonstra como o sistema reagiria em caso de uma seca prolongada de dez anos. Como foi visto, diminuiria bastante a produção de energia, mas não chegaria a zero\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_3 = remove_URL(teste_3)\n",
    "teste_3 = remove_punct(teste_3)\n",
    "teste_3 = remove_hifen(teste_3)\n",
    "teste_3 = remove_stopwords(teste_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_3 = tokenizer.texts_to_sequences([teste_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6544281]]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "predictions_t2 = model.predict(np.array(texto_3))\n",
    "print(predictions_t2)\n",
    "predictions_t2 = [1 if p > 0.5 else 0 for p in predictions_t2]\n",
    "\n",
    "print(predictions_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_4 = \"A relativização da coisa julgada atualmente ganha grande notoriedade no sistema jurídico brasileiro, o que se revela, de certo modo, um meio de buscar e atingir uma justiça plena, ou seja, busca-se garantir maior segurança e evitar prejuízos às relações jurídico-sociais. Sendo assim, não é de se espantar que a relativização da coisa julgada tenha ganhado destaque nos últimos tempos, visto que as relações tendem a se tornar cada vez mais complexas e difíceis, o acerto se faz algo nem sempre tão exato. O artigo 467 do CPC, em linhas gerais, diz que a coisa julgada torna indiscutível e imutável a decisão, não mais sujeita a recurso ordinário ou extraordinário. O texto faz referência a chamada coisa julgada material, a qual tem seus efeitos além processo, ou seja, extrapolam o âmbito processual, bem como impede de rediscuti-lo e vincula o magistrado à sua decisão. A coisa julgada material é garantia constitucional (art. 5º, XXXVI, CF) e protegida em nível de cláusula pétrea, logo inerente ao Estado democrático de direito e ao acesso ao Judiciário, portanto relativizar a coisa julgada seria apenas possível através de uma Assembléia Constituinte Originária. Todavia a dinâmica da sociedade fez necessária, em alguns casos, sua relativização, já que um dos principais ideais é buscar sempre atingir a justiça, mesmo que para isso haja detrimento da segurança jurídica...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_4 = remove_URL(teste_4)\n",
    "teste_4 = remove_punct(teste_4)\n",
    "teste_4 = remove_hifen(teste_4)\n",
    "teste_4 = remove_stopwords(teste_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_4 = tokenizer.texts_to_sequences([teste_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.31666815]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "predictions_t5 = model.predict(np.array(texto_4))\n",
    "print(predictions_t5)\n",
    "predictions_t5 = [1 if p > 0.5 else 0 for p in predictions_t5]\n",
    "\n",
    "print(predictions_t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_5 = \"A doutrina diverge nessa resposta. Tradicionalmente, os contratos e os negócios jurídicos não são considerados fonte do direito, por não se aplicarem a todos, buscando o interesse apenas das partes. Por outro lado, porém, outros doutrinadores dizem que, por constituir norma de vontade entre as partes, deve ser considerado como fonte do direito. De um modo geral, na linguagem jurídica, por sua força e obrigatoriedade, os contratos e negócios jurídicos são ditos como “LEI ENTRE AS PARTES”, do mesmo modo que a sentença é a lei viva, efetivamente aplicada ao caso concreto.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_5 = remove_URL(teste_5)\n",
    "teste_5 = remove_punct(teste_5)\n",
    "teste_5 = remove_hifen(teste_5)\n",
    "teste_5 = remove_stopwords(teste_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_5 = tokenizer.texts_to_sequences([teste_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3167343]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "predictions_t6 = model.predict(np.array(texto_5))\n",
    "print(predictions_t6)\n",
    "predictions_t6 = [1 if p > 0.5 else 0 for p in predictions_t6]\n",
    "\n",
    "print(predictions_t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_6 = \"Contamos com uma equipe altamente qualificada, entre eles engenheiros e técnicos especializados em recuperação de equipamentos industriais de grande porte, além de representantes externos com grande experiência em projetos especiais. Essa capacidade intelectual nos permite assumir trabalhos complexos com a segurança e a agilidade que os nossos clientes precisam.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(teste):\n",
    "    teste = remove_URL(teste)\n",
    "    teste = remove_punct(teste)\n",
    "    teste = remove_hifen(teste)\n",
    "    teste = remove_stopwords(teste)\n",
    "    return teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_6 = tokenizer.texts_to_sequences([prepare(teste_6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0.654972]], dtype=float32), [1])\n"
     ]
    }
   ],
   "source": [
    "def predict(teste):\n",
    "    predictions = model.predict(np.array(teste))\n",
    "    p2 = [1 if p > 0.5 else 0 for p in predictions]\n",
    "    return predictions,p2\n",
    "\n",
    "print(predict(teste_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_r = [ predictions_t2,  predictions_t5,  predictions_t6]\n",
    "result = [\"eletrica\" if p == 1 else \"direito\" for p in p_r[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['direito', 'direito', 'direito']\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
