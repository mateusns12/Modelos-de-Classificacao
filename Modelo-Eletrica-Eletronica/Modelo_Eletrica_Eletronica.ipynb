{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(nome_arquivo,shuffle):\n",
    "    ds = pd.read_csv(nome_arquivo,encoding=\"utf-8\")\n",
    "    if shuffle:\n",
    "        ds = ds.sample(frac=1)\n",
    "    ds['texto'] = ds['texto'].apply(str)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data(\"train.csv\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(820, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valor</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>0</td>\n",
       "      <td>Esta monografia apresenta o estudo e projeto d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>1</td>\n",
       "      <td>A osteoporose é uma doença do esqueleto caract...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1</td>\n",
       "      <td>Esse trabalho apresenta a concepção e implemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1</td>\n",
       "      <td>Os parâmetros S são uma importante ferramenta ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>1</td>\n",
       "      <td>O objetivo deste trabalho é o desenvolvimento ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     valor                                              texto\n",
       "654      0  Esta monografia apresenta o estudo e projeto d...\n",
       "378      1  A osteoporose é uma doença do esqueleto caract...\n",
       "120      1  Esse trabalho apresenta a concepção e implemen...\n",
       "172      1  Os parâmetros S são uma importante ferramenta ...\n",
       "322      1  O objetivo deste trabalho é o desenvolvimento ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "654    Esta monografia apresenta o estudo e projeto d...\n",
       "378    A osteoporose é uma doença do esqueleto caract...\n",
       "120    Esse trabalho apresenta a concepção e implemen...\n",
       "172    Os parâmetros S são uma importante ferramenta ...\n",
       "322    O objetivo deste trabalho é o desenvolvimento ...\n",
       "                             ...                        \n",
       "645    Nesta monografia, analisou-se as consequências...\n",
       "709    Nos últimos anos a Geração Distribuída (GD) te...\n",
       "741    Nos últimos anos, notou-se um grande crescimen...\n",
       "414    Este projeto tem por objetivo o desenvolviment...\n",
       "195    Os campos da robótica e biologia apresentam di...\n",
       "Name: texto, Length: 820, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410\n",
      "410\n"
     ]
    }
   ],
   "source": [
    "print((df.valor==1).sum())#eletronica\n",
    "print((df.valor==0).sum())#eletrica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = set(stopwords.words(\"portuguese\"))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    filtered_words = [word.lower() for word in text.split() if word.lower() not in stop]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "def remove_URL(text):\n",
    "    url = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "    return url.sub(r\"\",text)\n",
    "\n",
    "def remove_punct(text):\n",
    "    translator = str.maketrans(\"\",\"\",'!\"\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~º')\n",
    "    translator = str.maketrans(\"\",\"\",'!\"\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~º')\n",
    "    return text.translate(translator)\n",
    "\n",
    "def remove_numbers(text):\n",
    "    result = ''.join([i for i in text if not i.isdigit()])\n",
    "    return result\n",
    "\n",
    "def remove_hifen(text):\n",
    "    translator = str.maketrans('-',' ')\n",
    "    return text.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r\"https?//(\\S+|www)\\.\\S+\")\n",
    "def pat(df_t):\n",
    "    for t in df_t.texto:\n",
    "        matches = pattern.findall(t)\n",
    "        for match in  matches:\n",
    "            print(t)\n",
    "            print(match)\n",
    "            print(pattern.sub(r\"\",t))        \n",
    "        if len(matches)> 0:\n",
    "            break\n",
    "pat(df)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test(df_t):\n",
    "    df_t[\"texto\"] = df_t.texto.map(remove_URL)\n",
    "    df_t[\"texto\"] = df_t.texto.map(remove_punct)\n",
    "    df_t[\"texto\"] = df_t.texto.map(remove_hifen)\n",
    "    df_t[\"texto\"] = df_t.texto.map(remove_numbers)\n",
    "    df_t[\"texto\"] = df_t.texto.map(remove_stopwords)\n",
    "\n",
    "make_test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def counter_word(text_col):\n",
    "    count = Counter()\n",
    "    for text in text_col.values:\n",
    "        for word in text.split():\n",
    "            count[word] += 1\n",
    "    return count\n",
    "\n",
    "counter = counter_word(df.texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11773"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sistema', 1066),\n",
       " ('trabalho', 940),\n",
       " ('energia', 686),\n",
       " ('projeto', 466),\n",
       " ('elétrica', 404)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_words = len(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(df,size):\n",
    "    train_size = int(df.shape[0]*size)\n",
    "    train_df = df[:train_size]\n",
    "    val_df = df[train_size:]\n",
    "    return train_df, val_df\n",
    "\n",
    "train_df, val_df = data_split(df,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656\n",
      "164\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_numpy(df):    \n",
    "    train_sentences = train_df.texto.to_numpy()\n",
    "    train_labels = train_df.valor.to_numpy()\n",
    "    val_sentences = val_df.texto.to_numpy()\n",
    "    val_labels = val_df.valor.to_numpy()\n",
    "    return train_sentences, train_labels, val_sentences, val_labels\n",
    "\n",
    "train_sentences, train_labels, val_sentences, val_labels = data_to_numpy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((656,), (164,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences.shape, val_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words = num_unique_words,oov_token=\"<OOV>\")\n",
    "\n",
    "def tokenization(df):      \n",
    "    tokenizer.fit_on_texts(train_sentences)\n",
    "    word_index = tokenizer.word_index\n",
    "    train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "    val_sequences = tokenizer.texts_to_sequences(val_sentences)\n",
    "    return train_sequences, val_sequences, word_index\n",
    "\n",
    "train_sequences, val_sequences, word_index = tokenization(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "#val_sequences = tokenizer.texts_to_sequences(val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((656, 600), (164, 600))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_length = 600\n",
    "\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding = \"post\",truncating = \"post\")\n",
    "val_padded = pad_sequences(val_sequences, maxlen = max_length, padding = \"post\", truncating = \"post\")\n",
    "train_padded.shape, val_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = dict([(idx,word) for (word, idx) in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(sequence):\n",
    "    return \" \".join([reverse_word_index.get(idx, \"?\") for idx in sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 211, 233, 13, 709, 938, 2662, 200, 561, 63, 11, 2663, 21, 2664, 16, 1080, 4, 2265, 2665, 184, 200, 561, 534, 876, 125, 167, 45, 18, 3208, 132, 159, 4071, 1171, 5741, 1080, 4, 2665, 313, 602, 160, 3209, 1080, 4, 2265, 2665, 16, 4072, 30, 515, 325, 4073, 1080, 30, 1723, 599, 79, 877, 4, 2665, 51, 215, 3196, 115, 1080, 6, 132, 200, 561, 534, 876, 151, 369, 1172, 1282, 383, 1080, 2666, 31, 1014, 263, 3210, 633, 53, 599, 247]\n",
      "trabalho visa realização estudo determinação diferenças introduzidas planejamento energético operação sistemas hidrotérmicos potência variar forma representação energia natural afluente atualmente planejamento energético médio prazo brasil realizado utilização software newave utilizada duas mil séries sintéticas representação energia afluente modelagem aqui proposta sugere representação energia natural afluente forma determinística meio média longo termo representação meio múltiplos cenários obtidos histórico energia afluente testes realizados indicarão melhor representação ser utilizada planejamento energético médio prazo quais vantagens eou desvantagens principalmente representação vazões apresenta menores custos operativos frente diferentes cenários demanda\n"
     ]
    }
   ],
   "source": [
    "decoded_text = decode(train_sequences[10])\n",
    "\n",
    "print(train_sequences[10])\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 600, 32)           376736    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                3096      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 50        \n",
      "=================================================================\n",
      "Total params: 400,618\n",
      "Trainable params: 400,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.Embedding(num_unique_words, 32, input_length = max_length))\n",
    "\n",
    "#model.add(layers.LSTM(256,dropout = 0.1))\n",
    "model.add(layers.GlobalAveragePooling1D())\n",
    "model.add(layers.Dense(128, activation = \"relu\"))\n",
    "model.add(layers.Dense(128, activation = \"relu\"))\n",
    "model.add(layers.Dense(24, activation = \"relu\"))\n",
    "model.add(layers.Dense(2, activation = \"softmax\"))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "optim = keras.optimizers.Adam(lr=0.001)\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "model.compile(loss=loss, optimizer = optim, metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "21/21 - 1s - loss: 0.6938 - accuracy: 0.4878 - val_loss: 0.6932 - val_accuracy: 0.4817\n",
      "Epoch 2/20\n",
      "21/21 - 0s - loss: 0.6931 - accuracy: 0.5107 - val_loss: 0.6931 - val_accuracy: 0.4695\n",
      "Epoch 3/20\n",
      "21/21 - 0s - loss: 0.6926 - accuracy: 0.5076 - val_loss: 0.6925 - val_accuracy: 0.5854\n",
      "Epoch 4/20\n",
      "21/21 - 0s - loss: 0.6905 - accuracy: 0.6082 - val_loss: 0.6898 - val_accuracy: 0.7317\n",
      "Epoch 5/20\n",
      "21/21 - 0s - loss: 0.6808 - accuracy: 0.6814 - val_loss: 0.6754 - val_accuracy: 0.7805\n",
      "Epoch 6/20\n",
      "21/21 - 0s - loss: 0.6162 - accuracy: 0.8308 - val_loss: 0.6163 - val_accuracy: 0.7195\n",
      "Epoch 7/20\n",
      "21/21 - 0s - loss: 0.4310 - accuracy: 0.8674 - val_loss: 0.5328 - val_accuracy: 0.7317\n",
      "Epoch 8/20\n",
      "21/21 - 0s - loss: 0.2287 - accuracy: 0.9345 - val_loss: 0.5947 - val_accuracy: 0.7256\n",
      "Epoch 9/20\n",
      "21/21 - 0s - loss: 0.1310 - accuracy: 0.9466 - val_loss: 0.6264 - val_accuracy: 0.7378\n",
      "Epoch 10/20\n",
      "21/21 - 0s - loss: 0.0748 - accuracy: 0.9817 - val_loss: 0.6212 - val_accuracy: 0.7805\n",
      "Epoch 11/20\n",
      "21/21 - 0s - loss: 0.0382 - accuracy: 0.9970 - val_loss: 0.6595 - val_accuracy: 0.7805\n",
      "Epoch 12/20\n",
      "21/21 - 0s - loss: 0.0199 - accuracy: 0.9970 - val_loss: 0.7320 - val_accuracy: 0.7622\n",
      "Epoch 13/20\n",
      "21/21 - 0s - loss: 0.0148 - accuracy: 0.9970 - val_loss: 0.7264 - val_accuracy: 0.7805\n",
      "Epoch 14/20\n",
      "21/21 - 0s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.7629 - val_accuracy: 0.7683\n",
      "Epoch 15/20\n",
      "21/21 - 0s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.7735 - val_accuracy: 0.7866\n",
      "Epoch 16/20\n",
      "21/21 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.7959 - val_accuracy: 0.7805\n",
      "Epoch 17/20\n",
      "21/21 - 0s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.8167 - val_accuracy: 0.7805\n",
      "Epoch 18/20\n",
      "21/21 - 0s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8359 - val_accuracy: 0.7744\n",
      "Epoch 19/20\n",
      "21/21 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.8683 - val_accuracy: 0.7622\n",
      "Epoch 20/20\n",
      "21/21 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8689 - val_accuracy: 0.7805\n",
      "\n",
      "Finished in 2.77 second(s)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.perf_counter()\n",
    "model.fit(train_padded,train_labels, epochs = 20, validation_data=(val_padded,val_labels), verbose=2)\n",
    "finish = time.perf_counter()\n",
    "print(f'\\nFinished in {round(finish-start, 2)} second(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(val_padded)\n",
    "print([np.argmax(element) for element in predictions])\n",
    "\n",
    "#predictions = [1 if p > 0.5 else 0 for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  1\n",
      "Resultado:  [0.11804704 0.88195294] \n",
      "\n",
      "[0 1 1 1 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1 1 0 1 0 1 1 0 0 1\n",
      " 1 1 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 1 0 1 1 1 1\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0\n",
      " 0 0 1 0 0 0 1 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0\n",
      " 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1] \n",
      "\n",
      "[[9.9993181e-01 6.8208152e-05]\n",
      " [7.8590488e-01 2.1409515e-01]\n",
      " [3.7417797e-04 9.9962580e-01]\n",
      " [1.9376443e-04 9.9980623e-01]\n",
      " [9.9873263e-01 1.2673312e-03]\n",
      " [8.6250831e-04 9.9913752e-01]\n",
      " [9.9911386e-01 8.8607409e-04]\n",
      " [1.1804704e-01 8.8195294e-01]\n",
      " [5.6490165e-01 4.3509838e-01]\n",
      " [5.2320473e-03 9.9476802e-01]\n",
      " [9.6204740e-01 3.7952565e-02]\n",
      " [9.9854857e-01 1.4513747e-03]\n",
      " [9.9814844e-01 1.8516252e-03]\n",
      " [1.5023846e-05 9.9998498e-01]\n",
      " [5.3517397e-02 9.4648260e-01]\n",
      " [9.9731195e-01 2.6880482e-03]\n",
      " [9.9121958e-01 8.7803658e-03]\n",
      " [2.5971059e-03 9.9740285e-01]\n",
      " [1.2489156e-01 8.7510848e-01]\n",
      " [9.9982315e-01 1.7691849e-04]\n",
      " [6.8673348e-01 3.1326655e-01]\n",
      " [1.3256667e-04 9.9986744e-01]\n",
      " [9.8064560e-01 1.9354455e-02]\n",
      " [7.3229694e-01 2.6770303e-01]\n",
      " [7.8629646e-03 9.9213701e-01]\n",
      " [8.5662645e-01 1.4337353e-01]\n",
      " [1.4483567e-03 9.9855167e-01]\n",
      " [1.9669371e-02 9.8033065e-01]\n",
      " [1.6134740e-01 8.3865267e-01]\n",
      " [9.2760402e-01 7.2395995e-02]\n",
      " [2.5834638e-01 7.4165362e-01]\n",
      " [9.9855250e-01 1.4475307e-03]\n",
      " [2.5835324e-03 9.9741650e-01]\n",
      " [8.0064428e-01 1.9935574e-01]\n",
      " [3.1088360e-02 9.6891159e-01]\n",
      " [9.9843687e-01 1.5631747e-03]\n",
      " [3.0592998e-04 9.9969411e-01]\n",
      " [3.1837469e-03 9.9681622e-01]\n",
      " [9.9883765e-01 1.1623857e-03]\n",
      " [5.6465054e-01 4.3534938e-01]\n",
      " [9.9970919e-01 2.9077203e-04]\n",
      " [9.9764270e-01 2.3572741e-03]\n",
      " [6.8377638e-01 3.1622368e-01]\n",
      " [9.9909532e-01 9.0466009e-04]\n",
      " [9.7846413e-01 2.1535886e-02]\n",
      " [1.5321539e-01 8.4678459e-01]\n",
      " [2.0462589e-04 9.9979538e-01]\n",
      " [9.9876237e-01 1.2376232e-03]\n",
      " [9.8705715e-01 1.2942822e-02]\n",
      " [2.3323485e-01 7.6676518e-01]\n",
      " [9.6948761e-01 3.0512419e-02]\n",
      " [9.9839753e-01 1.6024765e-03]\n",
      " [7.9573536e-01 2.0426461e-01]\n",
      " [9.9916065e-01 8.3930790e-04]\n",
      " [8.6278527e-04 9.9913722e-01]\n",
      " [4.0052412e-03 9.9599469e-01]\n",
      " [9.9570918e-01 4.2908601e-03]\n",
      " [5.5653084e-04 9.9944347e-01]\n",
      " [1.2670754e-04 9.9987328e-01]\n",
      " [9.6018630e-01 3.9813742e-02]\n",
      " [9.9971479e-01 2.8514469e-04]\n",
      " [3.5105906e-02 9.6489412e-01]\n",
      " [6.6401070e-01 3.3598930e-01]\n",
      " [9.9097049e-01 9.0294555e-03]\n",
      " [9.9957544e-01 4.2452486e-04]\n",
      " [9.9712509e-01 2.8749232e-03]\n",
      " [6.5182179e-01 3.4817824e-01]\n",
      " [5.8659304e-02 9.4134068e-01]\n",
      " [6.8484046e-02 9.3151599e-01]\n",
      " [9.9975735e-01 2.4268826e-04]\n",
      " [1.7244322e-02 9.8275572e-01]\n",
      " [8.5475385e-01 1.4524619e-01]\n",
      " [3.0137855e-04 9.9969864e-01]\n",
      " [1.4855377e-04 9.9985147e-01]\n",
      " [9.9926049e-01 7.3944504e-04]\n",
      " [9.6122193e-01 3.8778011e-02]\n",
      " [9.9972981e-01 2.7013972e-04]\n",
      " [4.7251567e-01 5.2748436e-01]\n",
      " [4.5326794e-03 9.9546731e-01]\n",
      " [9.9887604e-01 1.1239374e-03]\n",
      " [1.4395158e-02 9.8560482e-01]\n",
      " [3.4312382e-02 9.6568763e-01]\n",
      " [9.8108739e-01 1.8912612e-02]\n",
      " [7.7663826e-05 9.9992228e-01]\n",
      " [5.4957002e-01 4.5043001e-01]\n",
      " [6.8632931e-01 3.1367067e-01]\n",
      " [1.7634579e-03 9.9823654e-01]\n",
      " [5.0701475e-01 4.9298519e-01]\n",
      " [2.9942818e-02 9.7005713e-01]\n",
      " [9.9872440e-01 1.2755527e-03]\n",
      " [9.9830139e-01 1.6985524e-03]\n",
      " [1.4241251e-01 8.5758752e-01]\n",
      " [9.9888307e-01 1.1169098e-03]\n",
      " [9.9590379e-01 4.0961872e-03]\n",
      " [2.0378316e-03 9.9796224e-01]\n",
      " [5.0263084e-02 9.4973689e-01]\n",
      " [9.7411579e-01 2.5884217e-02]\n",
      " [8.4297758e-01 1.5702242e-01]\n",
      " [9.9844509e-01 1.5549110e-03]\n",
      " [1.7709969e-02 9.8229009e-01]\n",
      " [7.6089353e-05 9.9992394e-01]\n",
      " [4.4872342e-03 9.9551278e-01]\n",
      " [3.4709966e-01 6.5290028e-01]\n",
      " [9.8038852e-01 1.9611463e-02]\n",
      " [2.3436276e-04 9.9976569e-01]\n",
      " [3.2082226e-03 9.9679178e-01]\n",
      " [4.3714911e-04 9.9956280e-01]\n",
      " [2.4238373e-01 7.5761628e-01]\n",
      " [3.9733216e-01 6.0266787e-01]\n",
      " [3.8008741e-03 9.9619907e-01]\n",
      " [9.5352840e-01 4.6471551e-02]\n",
      " [9.9983430e-01 1.6571455e-04]\n",
      " [3.3129358e-01 6.6870642e-01]\n",
      " [2.1440530e-01 7.8559464e-01]\n",
      " [9.9667478e-01 3.3252207e-03]\n",
      " [4.1136813e-05 9.9995887e-01]\n",
      " [1.0207558e-01 8.9792448e-01]\n",
      " [2.4645449e-01 7.5354552e-01]\n",
      " [1.3311151e-01 8.6688852e-01]\n",
      " [9.9820232e-01 1.7976511e-03]\n",
      " [2.0646401e-04 9.9979359e-01]\n",
      " [9.9706262e-01 2.9373262e-03]\n",
      " [1.7290591e-04 9.9982709e-01]\n",
      " [9.9994063e-01 5.9390917e-05]\n",
      " [1.8765044e-01 8.1234962e-01]\n",
      " [2.5565299e-04 9.9974436e-01]\n",
      " [1.4307222e-01 8.5692775e-01]\n",
      " [9.9960405e-01 3.9597118e-04]\n",
      " [1.9788228e-01 8.0211771e-01]\n",
      " [9.6022081e-01 3.9779212e-02]\n",
      " [9.9978107e-01 2.1898914e-04]\n",
      " [4.1605335e-01 5.8394659e-01]\n",
      " [9.9824274e-01 1.7573176e-03]\n",
      " [5.9115561e-03 9.9408841e-01]\n",
      " [9.2706531e-01 7.2934739e-02]\n",
      " [1.4993810e-02 9.8500615e-01]\n",
      " [4.3147098e-02 9.5685291e-01]\n",
      " [1.9825122e-05 9.9998021e-01]\n",
      " [9.6444196e-01 3.5558082e-02]\n",
      " [5.5956239e-01 4.4043767e-01]\n",
      " [4.2726558e-01 5.7273436e-01]\n",
      " [9.9983573e-01 1.6421535e-04]\n",
      " [9.8529923e-01 1.4700754e-02]\n",
      " [9.9856585e-01 1.4341212e-03]\n",
      " [1.9359584e-04 9.9980646e-01]\n",
      " [9.9886596e-01 1.1340805e-03]\n",
      " [1.4338499e-02 9.8566145e-01]\n",
      " [9.9812764e-01 1.8723148e-03]\n",
      " [5.6914085e-01 4.3085915e-01]\n",
      " [4.2073674e-02 9.5792633e-01]\n",
      " [9.9849164e-01 1.5083891e-03]\n",
      " [9.9741852e-01 2.5814984e-03]\n",
      " [9.2808533e-01 7.1914613e-02]\n",
      " [2.3459872e-02 9.7654015e-01]\n",
      " [6.8897818e-05 9.9993110e-01]\n",
      " [9.6343726e-02 9.0365630e-01]\n",
      " [5.2475471e-02 9.4752455e-01]\n",
      " [1.2424097e-03 9.9875760e-01]\n",
      " [9.1905856e-01 8.0941468e-02]\n",
      " [9.9993575e-01 6.4191780e-05]\n",
      " [9.9994493e-01 5.5061646e-05]\n",
      " [9.9750769e-01 2.4922926e-03]\n",
      " [9.8641169e-01 1.3588297e-02]\n",
      " [4.4158596e-04 9.9955839e-01]]\n"
     ]
    }
   ],
   "source": [
    "index = 7\n",
    "#print(val_sentences[index])\n",
    "#print(val_padded[index],'\\n')\n",
    "print(\"Label: \",val_labels[index])\n",
    "print(\"Resultado: \",predictions[index],'\\n')\n",
    "print(val_labels,'\\n')\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = get_data(\"eval.csv\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valor</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Este projeto visa uma nova abordagem para um s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Nesta monografia, é apresentada a proposta de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>O objetivo da monografia foi estudar como as t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>As células de carga são instrumentos versáteis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Na atualidade, a produção termelétrica partici...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   valor                                              texto\n",
       "0      1  Este projeto visa uma nova abordagem para um s...\n",
       "1      1  Nesta monografia, é apresentada a proposta de ...\n",
       "2      1  O objetivo da monografia foi estudar como as t...\n",
       "3      1  As células de carga são instrumentos versáteis...\n",
       "4      0  Na atualidade, a produção termelétrica partici..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat(df_t)\n",
    "make_test(df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    projeto visa nova abordagem sistema vigilância...\n",
       "1    nesta monografia apresentada proposta equipame...\n",
       "2    objetivo monografia estudar técnicas controle ...\n",
       "3    células carga instrumentos versáteis usados mo...\n",
       "4    atualidade produção termelétrica participa mar...\n",
       "5    neste trabalho apresentado projeto instalação ...\n",
       "6    trabalho intitulado “estimação preço demanda e...\n",
       "7    trabalho apresenta estudo sobre impactos causa...\n",
       "Name: texto, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = df_t.texto.to_numpy()\n",
    "test_labels = df_t.valor.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding = \"post\",truncating = \"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.5721414e-03 9.9742788e-01]\n",
      " [7.1325824e-02 9.2867416e-01]\n",
      " [9.8352700e-01 1.6473042e-02]\n",
      " [1.0946973e-02 9.8905307e-01]\n",
      " [9.9972707e-01 2.7290345e-04]\n",
      " [9.9971825e-01 2.8174731e-04]\n",
      " [9.3418986e-01 6.5810189e-02]\n",
      " [9.9984109e-01 1.5886356e-04]]\n"
     ]
    }
   ],
   "source": [
    "predictions_t = model.predict(test_padded)\n",
    "print(predictions_t)\n",
    "#predictions_t = [1 if p > 0.5 else 0 for p in predictions_t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objetivo monografia estudar técnicas controle linear utilizadas determinar controladores largamente conhecidos avr pss impactam margem estabilidade transitória sistema máquina versus barramento infinito omib one machine versus infinite bus adota modelo eixo gerador síncrono pólos salientes seguida estudam modelos avr pss apresentados norma ieee standard ieee standard adotando modelo pssa single input daquela norma equações diferenciais sistema numericamente integradas sistema então simulado sob perturbação resposta dinâmica analisada averiguadas ocorrências bifurcações hopf sistema função parâmetros controladores através parametrização autovalores análise comportamento local sistema equilíbrio traçam diagramas bifurcação sistema baseando teoria regiões estabilidade sistemas dinâmicos lineares simulações utilizadas desenvolver método força bruta mfb estimar região estabilidade sistema malha aberta controlado avr controlado avr pss saturadores excitação traçam regiões estabilidade variando alguns parâmetros ganhos controladores estimativas comparadas concluir acerca impactos controladores naquelo tamanho região estabilidade conclui enquanto sistema malha aberta possui maior região introdução controlador avr sistema extremamente deletéria região estabilidade sistema seguida pss expande região conseguinte introdução saturadores diminui significativamente tamanho além disso medida aumentam ganhos controcontroladores tamanho região tende diminuir consequentemente altos ganhos saturadores têm efeito detrimental tamanho região estabilidade margem estabilidade transitória sistemas elétricos potência\n",
      "[1 1 1 1 0 0 0 0]\n",
      "[1, 1, 0, 1, 0, 0, 0, 0]\n",
      "87.5 %\n"
     ]
    }
   ],
   "source": [
    "index = 6\n",
    "print(test_sentences[2])#[index])\n",
    "\n",
    "print(test_labels)#[index])\n",
    "#print(predictions_t)#[index])\n",
    "predictions_t = [np.argmax(element) for element in predictions_t]\n",
    "print(predictions_t)\n",
    "def precision_t():\n",
    "    counter = len(test_labels)\n",
    "    list_c = [i for i,j in zip(predictions_t,test_labels) if i == j]\n",
    "    return len(list_c)/counter*100\n",
    "\n",
    "print(precision_t(),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(teste):\n",
    "    teste = remove_URL(teste)\n",
    "    teste = remove_punct(teste)\n",
    "    teste = remove_hifen(teste)\n",
    "    teste = remove_stopwords(teste)    \n",
    "    return teste\n",
    "\n",
    "def predict(teste):\n",
    "    predictions = model.predict(np.array(teste)) \n",
    "    p1 = [np.argmax(element) for element in predictions]\n",
    "    if p1[0]:\n",
    "        print(\"Disciplina: Eletronica\")\n",
    "    else:\n",
    "        print(\"Disciplina: Elétrica\")\n",
    "    return predictions,p1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_1 = \"O objetivo deste trabalho é propor um algoritmo para realizar a identificação de padrões na vocalização suína, visando determinar o nível do bem-estar do animal. Tal análise foi proposta uma vez que o bem-estar animal é um assunto cada vez mais abordado no mundo todo, principalmente quando os animais são criados para o abate. Dessa forma, a criação de um método em que haja o mínimo de contato com os animais se faz importante, evitando que tal contato altere o comportamento do animal e, conseqüentemente, o resultado da análise de seu bem-estar. Por essas características, foi proposto um método de análise dos sons emitidos pelos suínos com base na utilização de uma Rede Neural Artificial do tipo Radial Basis Function, a qual possui como elementos de treinamento e operação um conjunto de características extraídas através da Transformada Discreta Wavelet de sinais sonoros pré-gravados. As características obtidas dos sinais foram as energias das bandas críticas relativas à Escala Bark e a diferença entre as energias das bandas adjacentes, além dimensão fractal do sinal. Através desse método foram analisados dois tipos de sinais sonoros: a vocalização de leitões saudáveis e de leitões acometidos por uma doença chamada Artrite Traumática; e a vocalização de suínos adultos em situações de conforto e desconforto. Os resultados demonstram que a análise proposta atingiu bons patamares de acerto na determinação do bem-estar do animal\"\n",
    "#eletronica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_1 = tokenizer.texts_to_sequences([prepare(teste_1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 600) for input KerasTensor(type_spec=TensorSpec(shape=(None, 600), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 136).\n",
      "Disciplina: Eletronica\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.00363937, 0.9963606 ]], dtype=float32), [1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(teste_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_2 = \"Neste projeto de formatura seria dada continuidade ao trabalho de iniciação científica, que consistiu na análise de métodos de coordenação de robôs móveis, ou seja métodos de controle de um conjunto de robôs para que esses assumam uma determinada formação com direção e distância entre eles pré-definidas. Sendo estudada primeiramente a cinemática do robô móvel e logo em seguida foi feita a análise de uma formação simples de líder-seguidor, considerando também a alternância da liderança entre os robôs. A partir desse ponto seria feita a implementação da simulação do algoritmo de controle de 6 robôs móveis em formação utilizando controle por grafos e sistemas lineares sujeitos a saltos markovianos\"\n",
    "#eletronica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_2 = tokenizer.texts_to_sequences([prepare(teste_2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disciplina: Elétrica\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[9.9943095e-01, 5.6906685e-04]], dtype=float32), [0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(teste_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
